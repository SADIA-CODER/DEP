import pandas as pd
from bs4 import BeautifulSoup
import requests

# URL of the Wikipedia page
url = 'https://en.wikipedia.org/wiki/List_of_largest_companies_in_the_United_States_by_revenue'

# Fetch the page content
page = requests.get(url)

# Parse the HTML content
soup = BeautifulSoup(page.content, 'html.parser')

# Find the table containing the data (assuming the second table on the page)
table = soup.find_all('table')[1]

# Extract column headers (assuming they are in <th> tags)
headers = table.find_all('th')
column_names = [header.text.strip() for header in headers]

# Create an empty DataFrame with column headers
df = pd.DataFrame(columns=column_names)

# Find all rows in the table body (assuming data rows are in <tr> tags)
rows = table.find_all('tr')[1:]  # Skip the first row as it contains headers again

# Iterate through each row to extract data
for row in rows:
    data = row.find_all('td')  # Assuming data is in <td> tags
    row_data = [td.text.strip() for td in data]
    # Append the row data as a new row in the DataFrame
    df.loc[len(df)] = row_data

# Print the DataFrame to verify
print(df.head())

# Specify the output path relative to your current directory
output_path = r'D:\BSSE 2022-2026\C++ CODING\Hello-World\Companies.csv'

# Save the DataFrame to CSV
df.to_csv(output_path, index=False)
